{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective : \n",
    "- Use Pyspark library\n",
    "- Perform EDA Statistical analysis\n",
    "    - Mean, Median , Standard deviation, Variance of Numerical columns\n",
    "    - Outliers check\n",
    "- Make generalize solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PySpark\\\\spark-3.1.1-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import SparkSession\n",
    "conf = pyspark.SparkConf().setAppName('appName').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "|gender|race/ethnicity|parental level of education|       lunch|test preparation course|math score|reading score|writing score|\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "|female|       group B|          bachelor's degree|    standard|                   none|        72|           72|           74|\n",
      "|female|       group C|               some college|    standard|              completed|        69|           90|           88|\n",
      "|female|       group B|            master's degree|    standard|                   none|        90|           95|           93|\n",
      "|  male|       group A|         associate's degree|free/reduced|                   none|        47|           57|           44|\n",
      "|  male|       group C|               some college|    standard|                   none|        76|           78|           75|\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###Read dataset using Pyspark\n",
    "### Observe first 5 rows\n",
    "df = spark.read.csv(r'C:\\Users\\sayli\\Desktop\\Data_Science_practice\\Apache Spark Udemy course\\StudentsPerformance.csv',header=True, \n",
    "    mode=\"DROPMALFORMED\")\n",
    "df.show(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data invistigate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- race/ethnicity: string (nullable = true)\n",
      " |-- parental level of education: string (nullable = true)\n",
      " |-- lunch: string (nullable = true)\n",
      " |-- test preparation course: string (nullable = true)\n",
      " |-- math score: string (nullable = true)\n",
      " |-- reading score: string (nullable = true)\n",
      " |-- writing score: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###Get the datatype of the dataframe\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- race/ethnicity: string (nullable = true)\n",
      " |-- parental level of education: string (nullable = true)\n",
      " |-- lunch: string (nullable = true)\n",
      " |-- test preparation course: string (nullable = true)\n",
      " |-- math score: float (nullable = true)\n",
      " |-- reading score: float (nullable = true)\n",
      " |-- writing score: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Convert the datatypes to get statistical significance \n",
    "df = df.withColumn('math score', df['math score'].cast('float'))\n",
    "df = df.withColumn('reading score', df['reading score'].cast('float'))\n",
    "df = df.withColumn('writing score', df['writing score'].cast('float'))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': 0,\n",
       " 'race/ethnicity': 0,\n",
       " 'parental level of education': 0,\n",
       " 'lunch': 0,\n",
       " 'test preparation course': 0,\n",
       " 'math score': 0,\n",
       " 'reading score': 0,\n",
       " 'writing score': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check for missing values\n",
    "Dict_Null = {col: df.filter(df[col].isNull()).count() for col in df.columns}\n",
    "Dict_Null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ststitical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|        math score|\n",
      "+-------+------------------+\n",
      "|  count|              1000|\n",
      "|   mean|            66.089|\n",
      "| stddev|15.163080096009454|\n",
      "|    min|               0.0|\n",
      "|    max|             100.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## check statistical significance \n",
    "df.describe('math score').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Function to get median of the particular column\n",
    "def get_median(col_name):\n",
    "    median=df.approxQuantile(col_name, [0.5], 0.25)\n",
    "    return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[57.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_median(\"math score\")\n",
    "#df.approxQuantile(\"math score\", [0.5], 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[59.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_median(\"reading score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[58.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_median(\"writing score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'math score': [57.0], 'reading score': [59.0], 'writing score': [58.0]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get median of all numerical columns\n",
    "median = {c : df.approxQuantile(c, [0.5], 0.25) for c,d in zip(df.columns, df.dtypes) if d[1] == \"float\"}\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|avg(reading score)|\n",
      "+------------------+\n",
      "|            69.169|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## find mean of reading score column\n",
    "df.agg({'reading score': 'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'math score': [Row(avg(math score)=66.089)],\n",
       " 'reading score': [Row(avg(reading score)=69.169)],\n",
       " 'writing score': [Row(avg(writing score)=68.054)]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get mean of all numerical columns\n",
    "mean = {c : df.agg({c: 'mean'}).collect() for c,d in zip(df.columns, df.dtypes) if d[1] == \"float\"}\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'math score': [Row(stddev(math score)=15.163080096009454)],\n",
       " 'reading score': [Row(stddev(reading score)=14.600191937252223)],\n",
       " 'writing score': [Row(stddev(writing score)=15.19565701086966)]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get std_deviation of all numerical columns\n",
    "std_deviation = {c : df.agg({c: 'stddev'}).collect() for c,d in zip(df.columns, df.dtypes) if d[1] == \"float\"}\n",
    "std_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'math score': [Row(variance(math score)=229.91899799799805)],\n",
       " 'reading score': [Row(variance(reading score)=213.16560460460482)],\n",
       " 'writing score': [Row(variance(writing score)=230.90799199199222)]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get variance of all numerical columns\n",
    "variance = {c : df.agg({c: 'variance'}).collect() for c,d in zip(df.columns, df.dtypes) if d[1] == \"float\"}\n",
    "variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### class to check statistical_analysis\n",
    "class stat_analysis():\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "     \n",
    "    def _calculate_median(self):\n",
    "        median = {c : self.df.approxQuantile(c, [0.5], 0.25) for c,d in zip(self.df.columns, self.df.dtypes) if d[1] == \"float\"}\n",
    "        return median\n",
    "    \n",
    "    def _calculate_mean(self):\n",
    "        mean = {c : self.df.agg({c: 'mean'}).collect() for c,d in zip(self.df.columns, self.df.dtypes) if d[1] == \"float\"}\n",
    "        return mean\n",
    "    \n",
    "    def _calculate_std_deviation(self):\n",
    "        std_deviation = {c : self.df.agg({c: 'stddev'}).collect() for c,d in zip(self.df.columns, self.df.dtypes) if d[1] == \"float\"}\n",
    "        return std_deviation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'math score': [57.0], 'reading score': [59.0], 'writing score': [58.0]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_analysis(df)._calculate_median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'math score': {'q1': 57.0, 'q3': 77.0},\n",
       " 'reading score': {'q1': 59.0, 'q3': 79.0},\n",
       " 'writing score': {'q1': 57.0, 'q3': 79.0}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = {\n",
    "    c: dict(\n",
    "        zip([\"q1\", \"q3\"], df.approxQuantile(c, [0.25, 0.75], 0))\n",
    "    )\n",
    "    for c,d in zip(df.columns, df.dtypes) if d[1] == \"float\"\n",
    "}\n",
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'math score': {'q1': 57.0, 'q3': 77.0, 'lower': 27.0, 'upper': 107.0}, 'reading score': {'q1': 59.0, 'q3': 79.0, 'lower': 29.0, 'upper': 109.0}, 'writing score': {'q1': 57.0, 'q3': 79.0, 'lower': 24.0, 'upper': 112.0}}\n"
     ]
    }
   ],
   "source": [
    "for c in bounds:\n",
    "    iqr = bounds[c]['q3'] - bounds[c]['q1']\n",
    "    bounds[c]['lower'] = bounds[c]['q1'] - (iqr * 1.5)\n",
    "    bounds[c]['upper'] = bounds[c]['q3'] + (iqr * 1.5)\n",
    "print(bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+--------------+-----------------+-----------------+\n",
      "|gender|race/ethnicity|parental level of education|       lunch|test preparation course|math score|reading score|writing score|math score_out|reading score_out|writing score_out|\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+--------------+-----------------+-----------------+\n",
      "|female|       group B|          bachelor's degree|    standard|                   none|      72.0|         72.0|         74.0|             0|                0|                0|\n",
      "|female|       group C|               some college|    standard|              completed|      69.0|         90.0|         88.0|             0|                0|                0|\n",
      "|female|       group B|            master's degree|    standard|                   none|      90.0|         95.0|         93.0|             0|                0|                0|\n",
      "|  male|       group A|         associate's degree|free/reduced|                   none|      47.0|         57.0|         44.0|             0|                0|                0|\n",
      "|  male|       group C|               some college|    standard|                   none|      76.0|         78.0|         75.0|             0|                0|                0|\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+--------------+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1=df.select(\n",
    "    \"*\",\n",
    "    *[\n",
    "        f.when(\n",
    "            f.col(c).between(bounds[c]['lower'], bounds[c]['upper']),\n",
    "            0\n",
    "        ).otherwise(1).alias(c+\"_out\") \n",
    "        for c,d in zip(df.columns, df.dtypes) if d[1] == \"float\"\n",
    "    ]\n",
    ")\n",
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Check the outliers using class and write all above mentioned functions \n",
    "class Outlier():\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "\n",
    "    def _calculate_bounds(self):\n",
    "        bounds = {\n",
    "            c: dict(\n",
    "                zip([\"q1\", \"q3\"], self.df.approxQuantile(c, [0.25, 0.75], 0))\n",
    "            )\n",
    "            for c, d in zip(self.df.columns, self.df.dtypes) if d[1] in [\"float\", \"int\"]\n",
    "        }\n",
    "\n",
    "        for c in bounds:\n",
    "            iqr = bounds[c]['q3'] - bounds[c]['q1']\n",
    "            bounds[c]['lower'] = bounds[c]['q1'] - (iqr * 1.5)\n",
    "            bounds[c]['upper'] = bounds[c]['q3'] + (iqr * 1.5)\n",
    "\n",
    "        return bounds\n",
    "\n",
    "\n",
    "    def _flag_outliers_df(self):\n",
    "        bounds = self._calculate_bounds()\n",
    "\n",
    "        outliers_col = [\n",
    "            f.when(\n",
    "                ~f.col(c).between(bounds[c]['lower'], bounds[c]['upper']),\n",
    "                f.col(c)\n",
    "            ).alias(c + '_outlier')\n",
    "            for c in bounds]\n",
    "\n",
    "        return self.df.select(*outliers_col)\n",
    "\n",
    "\n",
    "    def show_outliers(self):\n",
    "\n",
    "        outlier_df = self._flag_outliers_df()\n",
    "\n",
    "        for outlier in outlier_df.columns:\n",
    "            outlier_df.select(outlier).filter(f.col(outlier).isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|math score_outlier|\n",
      "+------------------+\n",
      "|              18.0|\n",
      "|               0.0|\n",
      "|              22.0|\n",
      "|              24.0|\n",
      "|              26.0|\n",
      "|              19.0|\n",
      "|              23.0|\n",
      "|               8.0|\n",
      "+------------------+\n",
      "\n",
      "+---------------------+\n",
      "|reading score_outlier|\n",
      "+---------------------+\n",
      "|                 17.0|\n",
      "|                 26.0|\n",
      "|                 28.0|\n",
      "|                 23.0|\n",
      "|                 24.0|\n",
      "|                 24.0|\n",
      "+---------------------+\n",
      "\n",
      "+---------------------+\n",
      "|writing score_outlier|\n",
      "+---------------------+\n",
      "|                 10.0|\n",
      "|                 22.0|\n",
      "|                 19.0|\n",
      "|                 15.0|\n",
      "|                 23.0|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Outlier(df).show_outliers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA Statistical analysis is performed using Pyspark on StudentsPerformance dataset. This analysis would provide basic understanding of Pyspark library and operations on dataframes using spark.\n",
    "#### Gereralized solution is developed to perform statistical analysis on the dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
